**Logistic Regresion**

import pandas as pd
import numpy as np
import os
import joblib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.linear_model import LogisticRegression
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,precision_score, recall_score, f1_score, roc_auc_score, classification_report, roc_curve
**Read Data File**
df=pd.read_csv("data.csv")
print(df.shape)
df.head(10)
**Understand the Data**
df.describe()
df.info()
**Drop unnecessary attribute**
df.drop(columns=["Unnamed: 0"],inplace=True)
print(df.shape)
**Split the data into Train, Test and Validate**
X=df.drop(columns="result")
Y=df["result"]
x_train,x_test_val,y_train,y_test_val=train_test_split(X,Y,test_size=0.3,train_size=0.7,random_state=42)
x_test,x_val,y_test,y_val=train_test_split(x_test_val,y_test_val,train_size=0.5,random_state=30)
print(len(x_train))
print(len(x_test))
print(len(x_val))
**Feature Scaling**
############ MnMax scaled ###################
Scaler=MinMaxScaler()
Scaler.fit(x_train)
x_train_scaled=Scaler.transform(x_train)
x_train_scaled=pd.DataFrame(x_train_scaled)
x_train_scaled.columns=x_train.columns
############ Standard scaled ###################
Scaler2=StandardScaler()
Scaler2.fit(x_train)
x_train_scaled2=Scaler.transform(x_train)
x_train_scaled2=pd.DataFrame(x_train_scaled2)
x_train_scaled2.columns=x_train.columns
########################################## 
print(x_train_scaled.head())
print("--------------------------------------------------------------------------------------------")
print(x_train_scaled2.head())
**Model Training**
model = LogisticRegression(max_iter=120)
model.fit(x_train_scaled, y_train)
""" note : max_iter (no. of optimization iterations done by model to find global minimum) is set by trial and error
           in order to get best results
"""

**Model Test**
x_test_scaled=pd.DataFrame(Scaler.transform(x_test))  #apply transformation to the test data directly with the same parameters of the training data to avoid data leakage
x_test_scaled.columns=x_test.columns
y_predict=model.predict(x_test_scaled)

accuracy=accuracy_score(y_test,y_predict)
print(accuracy)
confusion_mat=confusion_matrix(y_test,y_predict)
print(confusion_mat)


x_val_scaled=pd.DataFrame(Scaler.transform(x_val))
x_val_scaled.columns=x_val.columns
y_val_predict=model.predict(x_val_scaled)

confusion_mat_val=confusion_matrix(y_val,y_val_predict)
print(confusion_mat_val)
acc2=accuracy_score(y_val,y_val_predict)
print(acc2)
**Model Ealuation**
# Calculate evaluation metrics
precision = precision_score(y_val, y_val_predict)
recall = recall_score(y_val, y_val_predict)
f1 = f1_score(y_val, y_val_predict)
roc_auc = roc_auc_score(y_val, y_val_predict)

# Display the evaluation metrics
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("ROC AUC Score:", roc_auc)

# Print the confusion matrix and classification report
print("Confusion Matrix:")
conf_matrix = confusion_matrix(y_val, y_val_predict)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print("\nClassification Report:")
print(classification_report(y_val, y_val_predict))
**ROC Curve Results**
# Compute ROC curve
y_val_prob=model.predict_proba(x_val_scaled)[:,1]
fpr, tpr, thresholds = roc_curve(y_val, y_val_prob)

# Plot ROC curve
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f'GaussianNB (AUC = {roc_auc:.4f})')
plt.plot([0,1], [0,1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Gaussian Na√Øve Bayes')
plt.legend(loc='lower right')
plt.show()
**Export the Model**
# Define the directory to save the model
model_dir = 'models/logistic_regression/'

# Create the directory if it doesn't exist
os.makedirs(model_dir, exist_ok=True)

# Save the trained model
model_path = os.path.join(model_dir, 'logistic_regression_model.joblib')
joblib.dump(model, model_path)
print(f"Model saved to {model_path}")

# Also, save the scaler to ensure consistent preprocessing
scaler_path = os.path.join(model_dir, 'scaler.joblib')
joblib.dump(Scaler, scaler_path)
print(f"Scaler saved to {scaler_path}")
